@ На основе каких-то экспериментальных данных мы хотим получить модель, описывающую поведение системы. Предпочтительна аналитическая модель.

---

## В предыдущих сериях...

1. Выбрать уравнение регрессии (обеспечить аналитическое описание процесса)
2. По результатам опытов мы должны определить коэфф регрессии (должны провести столько опытов N чтобы обеспечить вычисление всех коэф. N >= k + 1, k - кол-во факторов)

$$\sum_{k=1}^{N} (y - \hat{y})^2 \rightarrow min$$

- $y$ - наблюденное значение,
- $\hat{y}$ - предсказанное значение.

$$B = (X^T X)^{-1}X^T Y$$

@ Некоторая интерполяционная формула.

Предпосылки (из теории вероятностей и мат. статистики):

1. $y_i$ - (значения выходной величины, получаемые в результе эксперимента) представляют собой независимые случайные величины, распределенные по нормальному закону.
2. $D\{y_u\}_{u=1,2,...,N - номер~~~эксперимента}$ (дисперсия полученных наблюденных значений) представляют собой одинаковые величины (равны).
3. Независимые переменные $x_1, x_2,..., x_N$ (факторы) измеряются с пренебрежимо малой погрешностью по сравнению со значениями $y_i$.

---

## Статистическая оценка уравнения регрессии

$\hat{Y}$ - предсказанное значение

$$\hat{Y} = XB$$

$$
\hat{Y} = \left|\begin{array}{c}
\hat{y_1} \\
\hat{y_2} \\
\cdots \\
\hat{y_N} \\
\end{array}\right|~~~~~

X = \left|\begin{array}{cccc}
x_{01} & x_{11} & \cdots & x_{N1} \\
x_{02} & x_{12} & \cdots & x_{N2} \\
\cdots & \cdots & \ddots & \cdots \\
x_{0K} & x_{1K} & \cdots & x_{NK} \\
\end{array}\right|~~~~~

B = \left|\begin{array}{c}
b_1 \\
b_2 \\
\cdots \\
b_N \\
\end{array}\right|
$$

$(\hat{Y} - Y)^T(\hat{Y} - Y) = \hat{Y}^T\hat{Y} - 2\hat{Y}^TY + Y^TY = (*)$

$\hat{Y}^T\hat{Y} = B^TX^TX(X^TX)^{-1}Y = B^TX^TY$

$\hat{Y}^TY = B^TX^TY$

$(*) = Y^TY - B^TX^TY$

--

$\displaystyle S_R = (yy) - \sum_{i=0}^{N}b_i(iy)$ - сумма остаточных квадратов.

$f_R = N - k - 1$ - кол-во степеней свободы.

$\displaystyle\sigma^2 = \frac{S_R}{f_R}$ - остаточная дисперсия

---

## Оценка погрешности коэффициентов уравнения регрессии

$B$ - вектор вычисленных коэффициентов.

$\beta$ - вектор теоретических значений функции.

$$\beta = M\{\beta\}$$

$$\Delta = Y - M{Y}$$

$M\{(B - M\{\beta\}) (B - M\{\beta\})\} = \dots = M\{(X^TX)^{-1}X\Delta\Delta^TX^T(X^TX)^{-1}\} = (X^TX) D\{y\}$

---

$(X^TX)^{-1}$ - матрица ошибок (кореляционная матрица).

Для удобства вычисления коэффициентов уравнения регрессии (сокращение трудоёмкости) удобно иметь дело с диагональной матрицей $C=X^TX$. Этого можно добиться, если проводить опыты в определённых точках. Опыты надо проводить в таких точках, которые обеспечивают ортогональность любых двух столбцов матрицы планирования.

Диагональный вид матрицы $C$ означает, что:

1. Коэффициенты уравнения регрессии вычисляются независимо друг от друга.
2. С позиции вычислений это означает, что при вычеркивании строки матрицы не придётся заново вычислять ранее вычисленные коэффициенты.
3. С позиции точности - рассматриваемый подход означает, что матрица ошибок имеет тоже диагональный вид, все коэффициенты вычисляются независимо друг от друга. Точность вычисления коэффициентов $\sigma\{Bz\}$ зависит только от точности выходной переменной $\sigma\{y\}$